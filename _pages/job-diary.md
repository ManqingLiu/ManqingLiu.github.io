---
layout: page
permalink: /job-diary/
title: job diary
nav: true
nav_order: 5
description: A diary tracking my job search.
toc:
  sidebar: left
giscus_comments: true
---

I'm graduating with my PhD in May 2026 and looking for what comes next. This diary is an honest, ongoing record of the process — the applications, the waiting, the small wins, the anxiety, and everything in between.

I'm sharing it publicly because job searching can feel isolating, and I hope reading about someone else's experience might help if you're going through something similar.

---

## Feb 22, 2026 

I've decided to keep a public diary of my job search, partly for accountability, partly because I think the process is worth documenting honestly.

Finding a job in the LLM/AI alignment field as a PhD student is super challenging. Working on finetuning LLMs taught me how important engineering skills are in AI safety research — building efficient architectures to speed up experiments, increasing the number of iterations, diagnosing unexpected crashes and failure modes. But this raises a question I keep coming back to: for a role that leans heavily on engineering, what comparative advantage do I have over college grads with a CS degree, or someone without a graduate degree but with many years of engineering experience?

I spent my first three years learning the "math" — probability, statistical inference, some coding classes. Most of my courses were heavily mathematical but not related to LLMs at all (even the machine learning classes were very classical ML, with the exception of maybe one NLP course I took at MIT).

My first dissertation project had nothing to do with LLMs. The second one tried to bridge the gap by introducing the doubly robust estimator in the value function for tree search, but it still wasn't on the core algorithms of LLMs themselves.

Then I joined a reading seminar on AI safety in the summer of 2024, and it got me intrigued when I found out that causality can be used in mechanistic interpretability. But it wasn't until the summer of 2025 that I really got firsthand experience with AI alignment research through the [MARS program](https://www.cambridgeaisafety.org/mars-old).

When I open LinkedIn job recommendations, I see roles related to LLMs in pretraining, posttraining, alignment, evals, and more — from FAANG, the top tier labs (OpenAI, Anthropic, Google DeepMind), and tons of startups founded by CS undergrads. People told me I just need to apply everywhere, that it's just a _numbers_ game. But since January, when I officially started applying, it has been a battle between: 1) applying selectively vs. casting a wide net to see what sticks; 2) managing timelines for different kinds of interviews (LeetCode style, ML coding, or something completely specific to a company's problems); and 3) most importantly, the mental strength to keep it together through rejections across N rounds of interviews, the unknown unknowns, and the fact that your peers found jobs in consulting relatively easily without going through endless rounds of interviews.

It's a bit overwhelming to find my place. So here I'm dumping my random thoughts to: 1) clarify my thinking; 2) log my progress on the job search; and 3) hopefully make someone in a similar situation feel a little less alone when they read these :)

Let the journey begin.

More soon.
